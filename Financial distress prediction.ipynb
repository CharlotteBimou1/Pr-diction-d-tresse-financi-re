{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projet de modélisation de détresse financière\n",
    "\n",
    "Dans ce kernel, nous allons nous intéressez au problème de stress financier auquel sont exposé les entreprise\n",
    "\n",
    "Pour ce faire, nous allons analyser un ensemble de données issues d'une ancienne compétition kaggle. L'ensemble des données traite de la prévision de détresse financière pour un échantillon d’entreprises. Mais avons, commencer par définir la notion de détressae financière afin de mieux cerner l'enjeux métier.\n",
    "\n",
    "### Fiancial stress analysis\n",
    "\n",
    "Les crises financières causent des ravages économiques, sociaux et politiques. Les politiques macroprudentielles gagnent du terrain, mais sont encore très peu étudiées par rapport à la politique monétaire et à la politique budgétaire. Nous utilisons le cadre général des prédictions séquentielles également appelé apprentissage automatique en ligne pour prévoir les crises hors échantillon.\n",
    "\n",
    "Le risque systémique financier est une question importante dans les systèmes économiques et financiers. En essayant de détecter et de réagir au risque systémique avec des quantités croissantes de données produites sur les marchés financiers et les systèmes, beaucoup de chercheurs ont de plus en plus utilisé des méthodes d’apprentissage automatique. Les méthodes d’apprentissage automatique étudient les mécanismes d’éclosion et de contagion du risque systémique dans le réseau financier et améliorent la réglementation actuelle du marché financier et de l’industrie. \n",
    "\n",
    "Ainsi dans ce kernel, nous nous basons sur les recherches et méthodologies existantes sur l’évaluation et la mesure du risque systémique financier combinées aux technologies d’apprentissage automatique, y compris l’analyse du Big Data, l’analyse du réseau et l’analyse des sentiments. Maintenant, intéressons nous aux données Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description des données\n",
    "\n",
    "Company: La société représente des entreprises échantillonnées.\n",
    "\n",
    "Time : Le temps montre différentes périodes de temps à laquelle appartiennent les données. La durée des séries horaires varie entre 1 et 14 pour chaque entreprise.\n",
    "\n",
    "Fiancial Ditress: La variable cible est indiquée par «détresse financière» si elle sera supérieure à -0,50, l’entreprise doit être considérée comme saine (0). Dans le cas contraire, il serait considéré comme financièrement en difficulté (1).\n",
    "\n",
    "Le rete des colonnes : Les caractéristiques indiquées par x1 à x83, sont quelques caractéristiques financières et non financières des sociétés échantillonnées. Ces caractéristiques appartiennent à la période précédente, qui devrait être utilisée pour prédire si l’entreprise sera financièrement en difficulté ou non (classification). Caractéristique x80 est variable catégorique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import de librairies nécessaire\n",
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>Financial Distress</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>...</th>\n",
       "      <th>x74</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>1.28100</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.87454</td>\n",
       "      <td>1.21640</td>\n",
       "      <td>0.060940</td>\n",
       "      <td>0.188270</td>\n",
       "      <td>0.52510</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>1.27000</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>1.00490</td>\n",
       "      <td>-0.014080</td>\n",
       "      <td>0.181040</td>\n",
       "      <td>0.62288</td>\n",
       "      <td>...</td>\n",
       "      <td>107.090</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.325390</td>\n",
       "      <td>1.05290</td>\n",
       "      <td>-0.059379</td>\n",
       "      <td>0.92242</td>\n",
       "      <td>0.72926</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.044865</td>\n",
       "      <td>0.43292</td>\n",
       "      <td>...</td>\n",
       "      <td>120.870</td>\n",
       "      <td>36.07</td>\n",
       "      <td>35.273</td>\n",
       "      <td>17.000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.566570</td>\n",
       "      <td>1.11310</td>\n",
       "      <td>-0.015229</td>\n",
       "      <td>0.85888</td>\n",
       "      <td>0.80974</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>0.091033</td>\n",
       "      <td>0.67546</td>\n",
       "      <td>...</td>\n",
       "      <td>54.806</td>\n",
       "      <td>39.80</td>\n",
       "      <td>38.377</td>\n",
       "      <td>17.167</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.325390</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>1.06230</td>\n",
       "      <td>0.107020</td>\n",
       "      <td>0.81460</td>\n",
       "      <td>0.83593</td>\n",
       "      <td>0.199960</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>29</td>\n",
       "      <td>1.251000</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>1.05580</td>\n",
       "      <td>0.081916</td>\n",
       "      <td>0.87949</td>\n",
       "      <td>0.68673</td>\n",
       "      <td>0.142630</td>\n",
       "      <td>0.043102</td>\n",
       "      <td>0.77198</td>\n",
       "      <td>...</td>\n",
       "      <td>107.090</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.200200</td>\n",
       "      <td>0.97059</td>\n",
       "      <td>0.076064</td>\n",
       "      <td>0.90677</td>\n",
       "      <td>0.80980</td>\n",
       "      <td>0.165920</td>\n",
       "      <td>-0.024649</td>\n",
       "      <td>0.73660</td>\n",
       "      <td>...</td>\n",
       "      <td>120.870</td>\n",
       "      <td>36.07</td>\n",
       "      <td>35.273</td>\n",
       "      <td>17.000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>29</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.234800</td>\n",
       "      <td>1.05900</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.81811</td>\n",
       "      <td>0.87599</td>\n",
       "      <td>0.234450</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>0.78727</td>\n",
       "      <td>...</td>\n",
       "      <td>54.806</td>\n",
       "      <td>39.80</td>\n",
       "      <td>38.377</td>\n",
       "      <td>17.167</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>29</td>\n",
       "      <td>1.200200</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.340500</td>\n",
       "      <td>1.12450</td>\n",
       "      <td>0.147840</td>\n",
       "      <td>0.75871</td>\n",
       "      <td>1.07990</td>\n",
       "      <td>0.276440</td>\n",
       "      <td>0.089408</td>\n",
       "      <td>0.80356</td>\n",
       "      <td>...</td>\n",
       "      <td>59.806</td>\n",
       "      <td>44.53</td>\n",
       "      <td>42.822</td>\n",
       "      <td>15.500</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.234800</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.047400</td>\n",
       "      <td>1.59980</td>\n",
       "      <td>0.262460</td>\n",
       "      <td>0.54615</td>\n",
       "      <td>1.31270</td>\n",
       "      <td>0.369480</td>\n",
       "      <td>0.296640</td>\n",
       "      <td>0.85364</td>\n",
       "      <td>...</td>\n",
       "      <td>66.262</td>\n",
       "      <td>52.74</td>\n",
       "      <td>49.206</td>\n",
       "      <td>15.500</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>29</td>\n",
       "      <td>1.340500</td>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2.345900</td>\n",
       "      <td>1.57560</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.56448</td>\n",
       "      <td>1.15650</td>\n",
       "      <td>0.348620</td>\n",
       "      <td>0.299840</td>\n",
       "      <td>0.85817</td>\n",
       "      <td>...</td>\n",
       "      <td>79.951</td>\n",
       "      <td>66.12</td>\n",
       "      <td>59.471</td>\n",
       "      <td>18.000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>29</td>\n",
       "      <td>2.047400</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2.249900</td>\n",
       "      <td>1.54430</td>\n",
       "      <td>0.240910</td>\n",
       "      <td>0.59073</td>\n",
       "      <td>1.07700</td>\n",
       "      <td>0.325610</td>\n",
       "      <td>0.301170</td>\n",
       "      <td>1.12100</td>\n",
       "      <td>...</td>\n",
       "      <td>84.660</td>\n",
       "      <td>73.20</td>\n",
       "      <td>63.880</td>\n",
       "      <td>16.000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>29</td>\n",
       "      <td>2.345900</td>\n",
       "      <td>14</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2.282600</td>\n",
       "      <td>1.72170</td>\n",
       "      <td>0.215250</td>\n",
       "      <td>0.55229</td>\n",
       "      <td>0.84101</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>0.333360</td>\n",
       "      <td>1.28690</td>\n",
       "      <td>...</td>\n",
       "      <td>93.883</td>\n",
       "      <td>82.30</td>\n",
       "      <td>74.497</td>\n",
       "      <td>16.500</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>29</td>\n",
       "      <td>2.249900</td>\n",
       "      <td>15</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.798200</td>\n",
       "      <td>1.72320</td>\n",
       "      <td>0.208630</td>\n",
       "      <td>0.53398</td>\n",
       "      <td>0.78651</td>\n",
       "      <td>0.293030</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>1.35480</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.000</td>\n",
       "      <td>17.125</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>29</td>\n",
       "      <td>2.282600</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2.827700</td>\n",
       "      <td>1.63070</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.54772</td>\n",
       "      <td>0.72819</td>\n",
       "      <td>0.273580</td>\n",
       "      <td>0.320850</td>\n",
       "      <td>1.10110</td>\n",
       "      <td>...</td>\n",
       "      <td>91.500</td>\n",
       "      <td>130.50</td>\n",
       "      <td>132.400</td>\n",
       "      <td>20.000</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>29</td>\n",
       "      <td>1.798200</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2.941300</td>\n",
       "      <td>2.17230</td>\n",
       "      <td>0.319450</td>\n",
       "      <td>0.44139</td>\n",
       "      <td>0.94698</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.481260</td>\n",
       "      <td>1.39200</td>\n",
       "      <td>...</td>\n",
       "      <td>87.100</td>\n",
       "      <td>175.90</td>\n",
       "      <td>178.100</td>\n",
       "      <td>20.000</td>\n",
       "      <td>14.5</td>\n",
       "      <td>-20.2</td>\n",
       "      <td>29</td>\n",
       "      <td>2.827700</td>\n",
       "      <td>18</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2.659800</td>\n",
       "      <td>2.09240</td>\n",
       "      <td>0.303480</td>\n",
       "      <td>0.43822</td>\n",
       "      <td>0.99193</td>\n",
       "      <td>0.426300</td>\n",
       "      <td>0.465320</td>\n",
       "      <td>1.49120</td>\n",
       "      <td>...</td>\n",
       "      <td>92.900</td>\n",
       "      <td>203.20</td>\n",
       "      <td>204.500</td>\n",
       "      <td>22.000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>29</td>\n",
       "      <td>2.941300</td>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2.232000</td>\n",
       "      <td>2.22630</td>\n",
       "      <td>0.325880</td>\n",
       "      <td>0.40651</td>\n",
       "      <td>0.90804</td>\n",
       "      <td>0.455340</td>\n",
       "      <td>0.493550</td>\n",
       "      <td>1.65280</td>\n",
       "      <td>...</td>\n",
       "      <td>91.700</td>\n",
       "      <td>227.50</td>\n",
       "      <td>214.500</td>\n",
       "      <td>21.000</td>\n",
       "      <td>20.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>29</td>\n",
       "      <td>2.659800</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.659900</td>\n",
       "      <td>0.87440</td>\n",
       "      <td>-0.034676</td>\n",
       "      <td>0.79350</td>\n",
       "      <td>0.60952</td>\n",
       "      <td>-0.002632</td>\n",
       "      <td>-0.086847</td>\n",
       "      <td>0.50609</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.303170</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.022750</td>\n",
       "      <td>0.83537</td>\n",
       "      <td>0.064310</td>\n",
       "      <td>0.61430</td>\n",
       "      <td>0.49359</td>\n",
       "      <td>0.097075</td>\n",
       "      <td>-0.096852</td>\n",
       "      <td>0.18896</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.006922</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company  Time  Financial Distress       x1        x2       x3       x4  \\\n",
       "0         1     1            0.010636  1.28100  0.022934  0.87454  1.21640   \n",
       "1         1     2           -0.455970  1.27000  0.006454  0.82067  1.00490   \n",
       "2         1     3           -0.325390  1.05290 -0.059379  0.92242  0.72926   \n",
       "3         1     4           -0.566570  1.11310 -0.015229  0.85888  0.80974   \n",
       "4         2     1            1.357300  1.06230  0.107020  0.81460  0.83593   \n",
       "5         2     2            0.007188  1.05580  0.081916  0.87949  0.68673   \n",
       "6         2     3            1.200200  0.97059  0.076064  0.90677  0.80980   \n",
       "7         2     4            2.234800  1.05900  0.130200  0.81811  0.87599   \n",
       "8         2     5            1.340500  1.12450  0.147840  0.75871  1.07990   \n",
       "9         2     6            2.047400  1.59980  0.262460  0.54615  1.31270   \n",
       "10        2     7            2.345900  1.57560  0.262100  0.56448  1.15650   \n",
       "11        2     8            2.249900  1.54430  0.240910  0.59073  1.07700   \n",
       "12        2     9            2.282600  1.72170  0.215250  0.55229  0.84101   \n",
       "13        2    10            1.798200  1.72320  0.208630  0.53398  0.78651   \n",
       "14        2    11            2.827700  1.63070  0.186230  0.54772  0.72819   \n",
       "15        2    12            2.941300  2.17230  0.319450  0.44139  0.94698   \n",
       "16        2    13            2.659800  2.09240  0.303480  0.43822  0.99193   \n",
       "17        2    14            2.232000  2.22630  0.325880  0.40651  0.90804   \n",
       "18        3     1           -1.659900  0.87440 -0.034676  0.79350  0.60952   \n",
       "19        4     1            0.022750  0.83537  0.064310  0.61430  0.49359   \n",
       "\n",
       "          x5        x6       x7  ...      x74     x75      x76     x77   x78  \\\n",
       "0   0.060940  0.188270  0.52510  ...   85.437   27.07   26.102  16.000  16.0   \n",
       "1  -0.014080  0.181040  0.62288  ...  107.090   31.31   30.194  17.000  16.0   \n",
       "2   0.020476  0.044865  0.43292  ...  120.870   36.07   35.273  17.000  15.0   \n",
       "3   0.076037  0.091033  0.67546  ...   54.806   39.80   38.377  17.167  16.0   \n",
       "4   0.199960  0.047800  0.74200  ...   85.437   27.07   26.102  16.000  16.0   \n",
       "5   0.142630  0.043102  0.77198  ...  107.090   31.31   30.194  17.000  16.0   \n",
       "6   0.165920 -0.024649  0.73660  ...  120.870   36.07   35.273  17.000  15.0   \n",
       "7   0.234450  0.045576  0.78727  ...   54.806   39.80   38.377  17.167  16.0   \n",
       "8   0.276440  0.089408  0.80356  ...   59.806   44.53   42.822  15.500  14.0   \n",
       "9   0.369480  0.296640  0.85364  ...   66.262   52.74   49.206  15.500  12.0   \n",
       "10  0.348620  0.299840  0.85817  ...   79.951   66.12   59.471  18.000  12.0   \n",
       "11  0.325610  0.301170  1.12100  ...   84.660   73.20   63.880  16.000  12.0   \n",
       "12  0.293500  0.333360  1.28690  ...   93.883   82.30   74.497  16.500  13.0   \n",
       "13  0.293030  0.329800  1.35480  ...  100.000  100.00  100.000  17.125  14.5   \n",
       "14  0.273580  0.320850  1.10110  ...   91.500  130.50  132.400  20.000  14.5   \n",
       "15  0.427400  0.481260  1.39200  ...   87.100  175.90  178.100  20.000  14.5   \n",
       "16  0.426300  0.465320  1.49120  ...   92.900  203.20  204.500  22.000  22.0   \n",
       "17  0.455340  0.493550  1.65280  ...   91.700  227.50  214.500  21.000  20.5   \n",
       "18 -0.002632 -0.086847  0.50609  ...   85.437   27.07   26.102  16.000  16.0   \n",
       "19  0.097075 -0.096852  0.18896  ...   85.437   27.07   26.102  16.000  16.0   \n",
       "\n",
       "     x79  x80       x81  x82  x83  \n",
       "0    0.2   22  0.060390   30   49  \n",
       "1    0.4   22  0.010636   31   50  \n",
       "2   -0.2   22 -0.455970   32   51  \n",
       "3    5.6   22 -0.325390   33   52  \n",
       "4    0.2   29  1.251000    7   27  \n",
       "5    0.4   29  1.357300    8   28  \n",
       "6   -0.2   29  0.007188    9   29  \n",
       "7    5.6   29  1.200200   10   30  \n",
       "8    2.1   29  2.234800   11   31  \n",
       "9   -6.4   29  1.340500   12   32  \n",
       "10 -13.4   29  2.047400   13   33  \n",
       "11   1.2   29  2.345900   14   34  \n",
       "12   0.6   29  2.249900   15   35  \n",
       "13  -7.0   29  2.282600   16   36  \n",
       "14 -16.0   29  1.798200   17   37  \n",
       "15 -20.2   29  2.827700   18   38  \n",
       "16   6.4   29  2.941300   19   39  \n",
       "17   8.6   29  2.659800   20   40  \n",
       "18   0.2   25 -0.303170    8   37  \n",
       "19   0.2   12  0.006922   28   44  \n",
       "\n",
       "[20 rows x 86 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('financial stress.csv')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par exemple, l’entreprise 1 est en difficulté financière à l’époque 4, mais l’entreprise 2 est toujours en bonne santé au moment 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values: 0\n"
     ]
    }
   ],
   "source": [
    "#Vérification de la présence de donnée manquantes\n",
    "\n",
    "print(\"Total missing values:\", df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3672, 86)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3672 entries, 0 to 3671\n",
      "Data columns (total 86 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Company             3672 non-null   int64  \n",
      " 1   Time                3672 non-null   int64  \n",
      " 2   Financial Distress  3672 non-null   float64\n",
      " 3   x1                  3672 non-null   float64\n",
      " 4   x2                  3672 non-null   float64\n",
      " 5   x3                  3672 non-null   float64\n",
      " 6   x4                  3672 non-null   float64\n",
      " 7   x5                  3672 non-null   float64\n",
      " 8   x6                  3672 non-null   float64\n",
      " 9   x7                  3672 non-null   float64\n",
      " 10  x8                  3672 non-null   float64\n",
      " 11  x9                  3672 non-null   float64\n",
      " 12  x10                 3672 non-null   float64\n",
      " 13  x11                 3672 non-null   float64\n",
      " 14  x12                 3672 non-null   float64\n",
      " 15  x13                 3672 non-null   float64\n",
      " 16  x14                 3672 non-null   float64\n",
      " 17  x15                 3672 non-null   float64\n",
      " 18  x16                 3672 non-null   float64\n",
      " 19  x17                 3672 non-null   float64\n",
      " 20  x18                 3672 non-null   float64\n",
      " 21  x19                 3672 non-null   float64\n",
      " 22  x20                 3672 non-null   float64\n",
      " 23  x21                 3672 non-null   float64\n",
      " 24  x22                 3672 non-null   float64\n",
      " 25  x23                 3672 non-null   float64\n",
      " 26  x24                 3672 non-null   float64\n",
      " 27  x25                 3672 non-null   float64\n",
      " 28  x26                 3672 non-null   float64\n",
      " 29  x27                 3672 non-null   float64\n",
      " 30  x28                 3672 non-null   float64\n",
      " 31  x29                 3672 non-null   float64\n",
      " 32  x30                 3672 non-null   float64\n",
      " 33  x31                 3672 non-null   float64\n",
      " 34  x32                 3672 non-null   float64\n",
      " 35  x33                 3672 non-null   float64\n",
      " 36  x34                 3672 non-null   float64\n",
      " 37  x35                 3672 non-null   float64\n",
      " 38  x36                 3672 non-null   float64\n",
      " 39  x37                 3672 non-null   float64\n",
      " 40  x38                 3672 non-null   float64\n",
      " 41  x39                 3672 non-null   float64\n",
      " 42  x40                 3672 non-null   float64\n",
      " 43  x41                 3672 non-null   float64\n",
      " 44  x42                 3672 non-null   float64\n",
      " 45  x43                 3672 non-null   float64\n",
      " 46  x44                 3672 non-null   float64\n",
      " 47  x45                 3672 non-null   float64\n",
      " 48  x46                 3672 non-null   float64\n",
      " 49  x47                 3672 non-null   float64\n",
      " 50  x48                 3672 non-null   float64\n",
      " 51  x49                 3672 non-null   float64\n",
      " 52  x50                 3672 non-null   float64\n",
      " 53  x51                 3672 non-null   float64\n",
      " 54  x52                 3672 non-null   float64\n",
      " 55  x53                 3672 non-null   float64\n",
      " 56  x54                 3672 non-null   float64\n",
      " 57  x55                 3672 non-null   float64\n",
      " 58  x56                 3672 non-null   float64\n",
      " 59  x57                 3672 non-null   float64\n",
      " 60  x58                 3672 non-null   float64\n",
      " 61  x59                 3672 non-null   float64\n",
      " 62  x60                 3672 non-null   float64\n",
      " 63  x61                 3672 non-null   float64\n",
      " 64  x62                 3672 non-null   float64\n",
      " 65  x63                 3672 non-null   float64\n",
      " 66  x64                 3672 non-null   float64\n",
      " 67  x65                 3672 non-null   float64\n",
      " 68  x66                 3672 non-null   float64\n",
      " 69  x67                 3672 non-null   float64\n",
      " 70  x68                 3672 non-null   float64\n",
      " 71  x69                 3672 non-null   float64\n",
      " 72  x70                 3672 non-null   float64\n",
      " 73  x71                 3672 non-null   float64\n",
      " 74  x72                 3672 non-null   float64\n",
      " 75  x73                 3672 non-null   float64\n",
      " 76  x74                 3672 non-null   float64\n",
      " 77  x75                 3672 non-null   float64\n",
      " 78  x76                 3672 non-null   float64\n",
      " 79  x77                 3672 non-null   float64\n",
      " 80  x78                 3672 non-null   float64\n",
      " 81  x79                 3672 non-null   float64\n",
      " 82  x80                 3672 non-null   int64  \n",
      " 83  x81                 3672 non-null   float64\n",
      " 84  x82                 3672 non-null   int64  \n",
      " 85  x83                 3672 non-null   int64  \n",
      "dtypes: float64(81), int64(5)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>Financial Distress</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>...</th>\n",
       "      <th>x74</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3.672000e+03</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "      <td>3672.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>182.084423</td>\n",
       "      <td>7.528322</td>\n",
       "      <td>1.040257</td>\n",
       "      <td>1.387820</td>\n",
       "      <td>0.129706</td>\n",
       "      <td>0.615769</td>\n",
       "      <td>8.681599e-01</td>\n",
       "      <td>0.154949</td>\n",
       "      <td>0.106717</td>\n",
       "      <td>0.784031</td>\n",
       "      <td>...</td>\n",
       "      <td>86.839822</td>\n",
       "      <td>91.920506</td>\n",
       "      <td>89.115908</td>\n",
       "      <td>17.780855</td>\n",
       "      <td>15.198708</td>\n",
       "      <td>-2.664305</td>\n",
       "      <td>19.714597</td>\n",
       "      <td>1.100488</td>\n",
       "      <td>13.122277</td>\n",
       "      <td>33.044935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>117.024636</td>\n",
       "      <td>4.064016</td>\n",
       "      <td>2.652227</td>\n",
       "      <td>1.452926</td>\n",
       "      <td>0.120013</td>\n",
       "      <td>0.177904</td>\n",
       "      <td>5.719519e-01</td>\n",
       "      <td>0.124904</td>\n",
       "      <td>0.210555</td>\n",
       "      <td>1.033606</td>\n",
       "      <td>...</td>\n",
       "      <td>16.706209</td>\n",
       "      <td>64.656504</td>\n",
       "      <td>64.349382</td>\n",
       "      <td>2.040152</td>\n",
       "      <td>2.828648</td>\n",
       "      <td>8.192663</td>\n",
       "      <td>7.508588</td>\n",
       "      <td>2.666733</td>\n",
       "      <td>9.465907</td>\n",
       "      <td>13.714563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-8.631700</td>\n",
       "      <td>0.075170</td>\n",
       "      <td>-0.258080</td>\n",
       "      <td>0.016135</td>\n",
       "      <td>5.350000e-07</td>\n",
       "      <td>-0.269790</td>\n",
       "      <td>-0.627750</td>\n",
       "      <td>0.035160</td>\n",
       "      <td>...</td>\n",
       "      <td>54.806000</td>\n",
       "      <td>24.318000</td>\n",
       "      <td>23.776000</td>\n",
       "      <td>15.250000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-20.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.499220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.172275</td>\n",
       "      <td>0.952145</td>\n",
       "      <td>0.048701</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>5.525575e-01</td>\n",
       "      <td>0.070001</td>\n",
       "      <td>-0.027754</td>\n",
       "      <td>0.436003</td>\n",
       "      <td>...</td>\n",
       "      <td>79.951000</td>\n",
       "      <td>39.800000</td>\n",
       "      <td>38.377000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.189912</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>168.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.583805</td>\n",
       "      <td>1.183600</td>\n",
       "      <td>0.107530</td>\n",
       "      <td>0.638690</td>\n",
       "      <td>7.752450e-01</td>\n",
       "      <td>0.131830</td>\n",
       "      <td>0.104325</td>\n",
       "      <td>0.641875</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>66.120000</td>\n",
       "      <td>59.471000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.594765</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>264.250000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.351750</td>\n",
       "      <td>1.506475</td>\n",
       "      <td>0.188685</td>\n",
       "      <td>0.749425</td>\n",
       "      <td>1.039000e+00</td>\n",
       "      <td>0.219570</td>\n",
       "      <td>0.231230</td>\n",
       "      <td>0.896773</td>\n",
       "      <td>...</td>\n",
       "      <td>93.883000</td>\n",
       "      <td>130.500000</td>\n",
       "      <td>132.400000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1.355050</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>422.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>128.400000</td>\n",
       "      <td>51.954000</td>\n",
       "      <td>0.749410</td>\n",
       "      <td>0.967900</td>\n",
       "      <td>6.835600e+00</td>\n",
       "      <td>0.858540</td>\n",
       "      <td>0.929550</td>\n",
       "      <td>38.836000</td>\n",
       "      <td>...</td>\n",
       "      <td>120.870000</td>\n",
       "      <td>227.500000</td>\n",
       "      <td>214.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>128.400000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company         Time  Financial Distress           x1           x2  \\\n",
       "count  3672.000000  3672.000000         3672.000000  3672.000000  3672.000000   \n",
       "mean    182.084423     7.528322            1.040257     1.387820     0.129706   \n",
       "std     117.024636     4.064016            2.652227     1.452926     0.120013   \n",
       "min       1.000000     1.000000           -8.631700     0.075170    -0.258080   \n",
       "25%      80.000000     4.000000            0.172275     0.952145     0.048701   \n",
       "50%     168.000000     7.000000            0.583805     1.183600     0.107530   \n",
       "75%     264.250000    11.000000            1.351750     1.506475     0.188685   \n",
       "max     422.000000    14.000000          128.400000    51.954000     0.749410   \n",
       "\n",
       "                x3            x4           x5           x6           x7  ...  \\\n",
       "count  3672.000000  3.672000e+03  3672.000000  3672.000000  3672.000000  ...   \n",
       "mean      0.615769  8.681599e-01     0.154949     0.106717     0.784031  ...   \n",
       "std       0.177904  5.719519e-01     0.124904     0.210555     1.033606  ...   \n",
       "min       0.016135  5.350000e-07    -0.269790    -0.627750     0.035160  ...   \n",
       "25%       0.501888  5.525575e-01     0.070001    -0.027754     0.436003  ...   \n",
       "50%       0.638690  7.752450e-01     0.131830     0.104325     0.641875  ...   \n",
       "75%       0.749425  1.039000e+00     0.219570     0.231230     0.896773  ...   \n",
       "max       0.967900  6.835600e+00     0.858540     0.929550    38.836000  ...   \n",
       "\n",
       "               x74          x75          x76          x77          x78  \\\n",
       "count  3672.000000  3672.000000  3672.000000  3672.000000  3672.000000   \n",
       "mean     86.839822    91.920506    89.115908    17.780855    15.198708   \n",
       "std      16.706209    64.656504    64.349382     2.040152     2.828648   \n",
       "min      54.806000    24.318000    23.776000    15.250000    12.000000   \n",
       "25%      79.951000    39.800000    38.377000    16.000000    13.000000   \n",
       "50%      90.000000    66.120000    59.471000    17.000000    14.500000   \n",
       "75%      93.883000   130.500000   132.400000    20.000000    16.000000   \n",
       "max     120.870000   227.500000   214.500000    22.000000    22.000000   \n",
       "\n",
       "               x79          x80          x81          x82          x83  \n",
       "count  3672.000000  3672.000000  3672.000000  3672.000000  3672.000000  \n",
       "mean     -2.664305    19.714597     1.100488    13.122277    33.044935  \n",
       "std       8.192663     7.508588     2.666733     9.465907    13.714563  \n",
       "min     -20.200000     1.000000    -0.499220     1.000000     2.000000  \n",
       "25%      -7.000000    14.000000     0.189912     6.000000    21.000000  \n",
       "50%       0.200000    20.000000     0.594765    11.000000    34.000000  \n",
       "75%       2.100000    26.000000     1.355050    17.000000    44.000000  \n",
       "max       8.600000    37.000000   128.400000    49.000000    74.000000  \n",
       "\n",
       "[8 rows x 86 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Time</th>\n",
       "      <th>Financial Distress</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>...</th>\n",
       "      <th>x74</th>\n",
       "      <th>x75</th>\n",
       "      <th>x76</th>\n",
       "      <th>x77</th>\n",
       "      <th>x78</th>\n",
       "      <th>x79</th>\n",
       "      <th>x80</th>\n",
       "      <th>x81</th>\n",
       "      <th>x82</th>\n",
       "      <th>x83</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>1.2810</td>\n",
       "      <td>0.022934</td>\n",
       "      <td>0.87454</td>\n",
       "      <td>1.21640</td>\n",
       "      <td>0.060940</td>\n",
       "      <td>0.188270</td>\n",
       "      <td>0.52510</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>30</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>1.2700</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.82067</td>\n",
       "      <td>1.00490</td>\n",
       "      <td>-0.014080</td>\n",
       "      <td>0.181040</td>\n",
       "      <td>0.62288</td>\n",
       "      <td>...</td>\n",
       "      <td>107.090</td>\n",
       "      <td>31.31</td>\n",
       "      <td>30.194</td>\n",
       "      <td>17.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0.010636</td>\n",
       "      <td>31</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.325390</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>-0.059379</td>\n",
       "      <td>0.92242</td>\n",
       "      <td>0.72926</td>\n",
       "      <td>0.020476</td>\n",
       "      <td>0.044865</td>\n",
       "      <td>0.43292</td>\n",
       "      <td>...</td>\n",
       "      <td>120.870</td>\n",
       "      <td>36.07</td>\n",
       "      <td>35.273</td>\n",
       "      <td>17.000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.455970</td>\n",
       "      <td>32</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.566570</td>\n",
       "      <td>1.1131</td>\n",
       "      <td>-0.015229</td>\n",
       "      <td>0.85888</td>\n",
       "      <td>0.80974</td>\n",
       "      <td>0.076037</td>\n",
       "      <td>0.091033</td>\n",
       "      <td>0.67546</td>\n",
       "      <td>...</td>\n",
       "      <td>54.806</td>\n",
       "      <td>39.80</td>\n",
       "      <td>38.377</td>\n",
       "      <td>17.167</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>22</td>\n",
       "      <td>-0.325390</td>\n",
       "      <td>33</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>1.0623</td>\n",
       "      <td>0.107020</td>\n",
       "      <td>0.81460</td>\n",
       "      <td>0.83593</td>\n",
       "      <td>0.199960</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.74200</td>\n",
       "      <td>...</td>\n",
       "      <td>85.437</td>\n",
       "      <td>27.07</td>\n",
       "      <td>26.102</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>29</td>\n",
       "      <td>1.251000</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Company  Time  Financial Distress      x1        x2       x3       x4  \\\n",
       "0        1     1            0.010636  1.2810  0.022934  0.87454  1.21640   \n",
       "1        1     2           -0.455970  1.2700  0.006454  0.82067  1.00490   \n",
       "2        1     3           -0.325390  1.0529 -0.059379  0.92242  0.72926   \n",
       "3        1     4           -0.566570  1.1131 -0.015229  0.85888  0.80974   \n",
       "4        2     1            1.357300  1.0623  0.107020  0.81460  0.83593   \n",
       "\n",
       "         x5        x6       x7  ...      x74    x75     x76     x77   x78  \\\n",
       "0  0.060940  0.188270  0.52510  ...   85.437  27.07  26.102  16.000  16.0   \n",
       "1 -0.014080  0.181040  0.62288  ...  107.090  31.31  30.194  17.000  16.0   \n",
       "2  0.020476  0.044865  0.43292  ...  120.870  36.07  35.273  17.000  15.0   \n",
       "3  0.076037  0.091033  0.67546  ...   54.806  39.80  38.377  17.167  16.0   \n",
       "4  0.199960  0.047800  0.74200  ...   85.437  27.07  26.102  16.000  16.0   \n",
       "\n",
       "   x79  x80       x81  x82  x83  \n",
       "0  0.2   22  0.060390   30   49  \n",
       "1  0.4   22  0.010636   31   50  \n",
       "2 -0.2   22 -0.455970   32   51  \n",
       "3  5.6   22 -0.325390   33   52  \n",
       "4  0.2   29  1.251000    7   27  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Distrees financières selon la parcelle d'heures de travail\n",
    "\n",
    "df=df.rename(columns={'Financial Distress':'Financial Distress'})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La description de Kaggle nous indique que si le nombre dans la colonne \"détresse financière\" est inférieur à -0,5, la société doit être considérée comme en difficulté.\n",
    "\n",
    "Nous pouvons imaginer qu'il s'agit d'une sorte de ratio financier - ratio des revenus sur le capital ou autre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du détresse financier en fonction du temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Financial Distress')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['Time'],df['Financial Distress'],color='red')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Financial Distress')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données\n",
    "\n",
    "1- Cherchons le nombre d'entreprises uniques.\n",
    "\n",
    "2- Vérifions combien de ces entreprises ont atteint un état de détresse (136 selon la description de Kaggle).\n",
    "\n",
    "3- Cherchon une liste des noms de caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422\n"
     ]
    }
   ],
   "source": [
    "total_n = len(df.groupby('Company')['Company'].nunique())\n",
    "print(total_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On identifie alors 422 entreprise uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136,)\n"
     ]
    }
   ],
   "source": [
    "distress_companies = df[df['Financial Distress'] < -0.5]\n",
    "u_distress = distress_companies['Company'].unique()\n",
    "print(u_distress.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On identifie effectivement 136 entreprises qui ont atteint un état de détresse financière. Cela indique que cet ensemble de données est déséquilibré et biaisées car on y compte 136 entreprises en difficulté financière contre 286 entreprises en bonne santé, c’est-à-dire que 136 entreprises de l’année sont en difficulté financière alors que 3546 entreprises en année sont en bonne santé. De ce fait, nous pourrions utilier le f-score comme critère d’évaluation du rendement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20', 'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30', 'x31', 'x32', 'x33', 'x34', 'x35', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41', 'x42', 'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64', 'x65', 'x66', 'x67', 'x68', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75', 'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83']\n"
     ]
    }
   ],
   "source": [
    "# Obtenons une liste de noms de caractéristiques des entreprises.\n",
    "\n",
    "feature_names = list(df.columns.values)[3:] \n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type d'apprentissage à appliquer\n",
    "\n",
    "Au vu de ces données, on peut faire avancer les hypothèses suivantes: \n",
    "    \n",
    "   1- Ces données peuvent être considérées comme un problème de classification.\n",
    "\n",
    "   2- Ces données pourraient également être considérées comme un problème de régression, puis le résultat sera converti en classification.\n",
    "\n",
    "   3- Ces données pourraient être considérées comme une classification multivarié des séries invariables.\n",
    "\n",
    "Les questions à se poser sont les suivantes: \n",
    "    \n",
    "   a- Quelles sont les caractéristiques les plus révélatrices de la détresse financière?\n",
    "\n",
    "   b- Quels types de modèles d’apprentissage automatique sont les plus performants sur cet ensemble de données ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choix du temps idéal pour séparer les données d'apprentissage et de test\n",
    "\n",
    "Pour mener à bien cette analyse, il convient de scinder les données en apprentissage, validation et test. Ainsi, afin de choisir une bonne date pour séparer le train et les essais, nous devrions idéalement choisir une date qui permette à la plupart des entités d'apparaître à la fois dans les données du train et des essais.\n",
    "\n",
    "Malheureusement, toutes les compagnies ne vivent pas pendant la même durée, donc si nous choisissons une date trop précoce ou trop tardive, nous risquons de retirer de nombreuses compagnies de la série de tests.\n",
    "\n",
    "Générons un histogramme des comptages pour chaque période afin de pouvoir choisir un endroit raisonnable pour la suppression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'Time'}>]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.hist(column=['Time'], bins=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons un léger déclin, puis une hausse dans l'histogramme autour de la période 10.\n",
    "\n",
    "Les baisses impliquent qu'une entreprise disparaît de l'ensemble de données, donc si nous fixons notre réduction autour de t=10, nous devrions encore obtenir un nombre décent de cas de détresse dans les données de formation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "5       1\n",
      "       ..\n",
      "418    13\n",
      "419    12\n",
      "420     1\n",
      "421     9\n",
      "422     7\n",
      "Name: Time, Length: 422, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(['Company'])['Time'].agg('min'))\n",
    "\n",
    "    # Nous pouvons voir que la plupart des entreprises commencent à la période 1, \n",
    "    # mais il y en a qui commencent leur vie beaucoup plus tard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérifions maintenant si la détresse se produit-elle de manière uniforme dans le temps dans ces entreprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'Time'}>]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEICAYAAABGaK+TAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATXklEQVR4nO3df4zkd33f8eeLMyjnWzg7MmzI2eo6lLhNfCTgbUuClOxijC4xsaMqUm0BtRvQtVVDnOhQYgu1VFXTnpo4FClV0xO4ZxXLq2CcgowS7JJs3UpAs2cMa2MIUXLFd3HuQA6Gda4xl7z7x85V6739MTvznZ39dJ8P6XTz/c58v9/XfWfmdd/97vdHqgpJUnteMu4AkqTBWOCS1CgLXJIaZYFLUqMscElqlAUuSY2ywLWrJHkyycy4c0hduGTcAaQuJVlaMXgp8JfAX/WG/3FV/eD2p5JGI57Io/9fJTkJvLuq/tu4s0ij4C4U7SpJTiZ5S+/xv0zy0SQfSfLtJItJvj/JXUnOJnk6yVtXTLs/yYeTPJPkdJJ/nWTP+P412u0scO12PwX8F+By4PPAp1j+XhwA/hXwn1a89l7gPPA3gdcDbwXevZ1hpZUscO12/6OqPlVV54GPAq8EjlbVd4A5YCrJZUkmgZ8AfqGqnq+qs8AHgFvGlly7nr/E1G53ZsXjc8A3quqvVgwDTADfC7wUeCbJhde/BHh6O0JKa7HApf48zfIRLVf0ttalsXMXitSHqnoGeBi4O8krkrwkyWuS/Pi4s2n3ssCl/v1D4GXAl4A/Bx4AXj3WRNrVPA5ckhrlFrgkNcoCl6RGWeCS1CgLXJIata3HgV9xxRU1NTW1nYvs2/PPP8++ffvGHWPLWs0NZh8Xs4/HMNlPnDjxjap65erx21rgU1NTLCwsbOci+zY/P8/MzMy4Y2xZq7nB7ONi9vEYJnuS/73WeHehSFKjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSo3b9LdWm7vwkAEcOnuf23uMunDx6Y2fzkqS1uAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJatSmBZ7kniRnkzyxavx7knwlyZNJ/t3oIkqS1tLPFvhx4NDKEUlmgZuB11XVDwK/1n00SdJGNi3wqnoUeHbV6H8KHK2qv+y95uwIskmSNpCq2vxFyRTwUFVd2xt+HPg4y1vm/wd4b1X9wTrTHgYOA0xOTl43NzfXSfCuLJ5+DoDJvXDmXHfzPXhgf3cz28DS0hITExPbsqyuDZr9wnvWpa2+X7txve8EuzX77OzsiaqaXj1+0ItZXQJcDrwR+DvAbyX5vlrjf4OqOgYcA5ienq6ZmZkBFzkat6+4mNXdi91d2+vk22c6m9dG5ufn2WnrtF+DZu/yomMXbPX92o3rfScw+4sNehTKKeDBWva/gL8GruguliRpM4MW+H8F3gyQ5PuBlwHf6CiTJKkPm+4zSHI/MANckeQU8H7gHuCe3qGFLwC3rbX7RJI0OpsWeFXdus5T7+g4iyRpCzwTU5IaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZtWuBJ7klytnfzhtXPvTdJJfF2apK0zfrZAj/O8t3nXyTJVcANwNc6ziRJ6sOmBV5VjwLPrvHUB4BfAryVmiSNQfq5lWWSKeChqrq2N3wTcH1V3ZHkJDBdVWve1DjJYeAwwOTk5HVzc3MdRe/G4unnAJjcC2fOdTffgwf2dzezDSwtLTExMbEty+raoNkvvGdd2ur7tRvX+06wW7PPzs6eqKrp1eM3vSfmakkuBd4HvLWf11fVMeAYwPT0dM3MzGx1kSN1+52fBODIwfPcvbjl1bGuk2+f6WxeG5mfn2enrdN+DZr9wnvWpa2+X7txve8EZn+xQY5CeQ1wNfCF3tb3lcBjSb6ny2CSpI1teZOzqhaBV10Y3mwXiiRpNPo5jPB+4DPANUlOJXnX6GNJkjaz6RZ4Vd26yfNTnaWRJPXNMzElqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSo7o7d1zSRaZGcNo/wMmjN45kvmqLW+CS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRvVzQ4d7kpxN8sSKcb+a5MtJvpjkt5NcNtKUkqSL9LMFfhw4tGrcI8C1VfU64A+BuzrOJUnaxKYFXlWPAs+uGvdwVZ3vDX6W5RsbS5K2URf7wH8W+J0O5iNJ2oJU1eYvSqaAh6rq2lXj3wdMA3+/1plRksPAYYDJycnr5ubmhs3cqcXTzwEwuRfOnBtzmE0cPLD/onFLS0tMTEyMIc3wBs1+4T3r0lrrdiP9Zh9FVth63pV242dmJxgm++zs7Imqml49fuACT3Ib8E+A66vqL/oJMT09XQsLC32H3g4XrhZ35OB57l7c2RdnXOsKdPPz88zMzGx/mA4Mmn0UV/jb6tX9+s2+E69GuBs/MzvBMNmTrFngAzVWkkPALwM/3m95S5K61c9hhPcDnwGuSXIqybuA3wBeDjyS5PEkvzninJKkVTbdAq+qW9cY/eERZJEkbYFnYkpSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1Kidfe64JG2zUV3+4PihfZ3P0y1wSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqP6uSPPPUnOJnlixbjvTvJIkq/2/r58tDElSav1swV+HDi0atydwKer6rXAp3vDkqRttGmBV9WjwLOrRt8M3Nt7fC/w093GkiRtJlW1+YuSKeChqrq2N/zNqrpsxfN/XlVr7kZJchg4DDA5OXnd3NzcQEEXTz830HT9mtwLZ86NdBFDO3hg/0XjlpaWmJiYGEOa4Q2afRSfhbXW7Ub6zT6qz+1W8660Gz8zWzGq9+zq/XsGzj47O3uiqqZXjx95ga80PT1dCwsLW8n9/4zqAjMXHDl4nrsXd/a1vU4evfGicfPz88zMzGx/mA4Mmn0Un4W11u1G+s0+qs/tVvOutBs/M1sxyotZDZo9yZoFPuhRKGeSvLo341cDZwecjyRpQIMW+CeA23qPbwM+3k0cSVK/+jmM8H7gM8A1SU4leRdwFLghyVeBG3rDkqRttOlO36q6dZ2nru84iyRpCzwTU5IaZYFLUqMscElqlAUuSY2ywCWpURa4JDVqZ587rqZtdkrykYPnuX3El0jo11ZPn95J2bV7uQUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJatRQBZ7kF5M8meSJJPcn+a6ugkmSNjZwgSc5APw8MN272fEe4JaugkmSNjbsLpRLgL1JLgEuBf50+EiSpH6kqgafOLkD+BXgHPBwVb19jdccBg4DTE5OXjc3NzfQshZPPzdwzn5M7oUz50a6iJHoIvfBA/u7CbPKZu9Zq+scxp99mPdsaWmJiYmJDtNsn5XZR90JXbt6/56B1/vs7OyJqppePX7gAk9yOfAx4B8A3wQ+CjxQVR9Zb5rp6elaWFgYaHlbvdjQVh05eJ67F9u7tlcXuU8evbGjNC/Wz8WsWlznMP7sw7xn8/PzzMzMdBdmG63MPupO6NrxQ/sGXu9J1izwYXahvAX4k6r6elV9B3gQ+NEh5idJ2oJhCvxrwBuTXJokLN+l/qluYkmSNjNwgVfV54AHgMeAxd68jnWUS5K0iaF24lXV+4H3d5RFkrQFnokpSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWrUUAWe5LIkDyT5cpKnkvxIV8EkSRsb9rbaHwR+t6p+JsnLgEs7yCRJ6sPABZ7kFcCPAbcDVNULwAvdxJIkbSZVNdiEyQ+zfBPjLwE/BJwA7qiq51e97jBwGGBycvK6ubm5gZa3ePq5gabr1+ReOHNupIsYiVZzg9mHcfDA/oGnXVpaYmJiYs3nRv09G9a41/swrt6/Z931vpnZ2dkTVTW9evwwBT4NfBZ4U1V9LskHgW9V1T9fb5rp6elaWFgYaHlTd35yoOn6deTgee5eHHaP0vZrNTeYfRgnj9448LTz8/PMzMys+dyov2fDGvd6H8bxQ/vWXe+bSbJmgQ/zS8xTwKmq+lxv+AHgDUPMT5K0BQMXeFX9GfB0kmt6o65neXeKJGkbDPuzyHuA+3pHoPwx8I+GjyRJ6sdQBV5VjwMX7ZeRJI2eZ2JKUqMscElqlAUuSY2ywCWpURa4JDXKApekRrV5Tqq0yw1zyvuRg+e5fYefMq/+uAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjLHBJatTQBZ5kT5LPJ3moi0CSpP50sQV+B/BUB/ORJG3BUAWe5ErgRuBD3cSRJPUrVTX4xMkDwL8FXg68t6retsZrDgOHASYnJ6+bm5sbaFmLp58bOGc/JvfCmXMjXcRItJobzD4uZh+Pq/fvYWJiYqBpZ2dnT1TVRbevHPhiVkneBpytqhNJZtZ7XVUdA44BTE9P18zMui/d0KgvvnPk4HnuXmzv2l6t5gazj4vZx+P4oX0M2n/rGWYXypuAm5KcBOaANyf5SCepJEmbGrjAq+quqrqyqqaAW4Dfq6p3dJZMkrQhjwOXpEZ1sjOpquaB+S7mJUnqj1vgktQoC1ySGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNWrgAk9yVZLfT/JUkieT3NFlMEnSxoa5ocN54EhVPZbk5cCJJI9U1Zc6yiZJ2sAw98R8pqoe6z3+NvAUcKCrYJKkjaWqhp9JMgU8ClxbVd9a9dxh4DDA5OTkdXNzcwMtY/H0c0Om3NjkXjhzbqSLGIlWc4PZx8Xs43H1/j1MTEwMNO3s7OyJqppePX7oAk8yAfx34Feq6sGNXjs9PV0LCwsDLWfqzk8ONF2/jhw8z92LndwidFu1mhvMPi5mH4/jh/YxMzMz0LRJ1izwoY5CSfJS4GPAfZuVtySpW8MchRLgw8BTVfXr3UWSJPVjmC3wNwHvBN6c5PHen5/sKJckaRMD70yqqv8JpMMskqQt8ExMSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1Kjhr0n5qEkX0nyR0nu7CqUJGlzw9wTcw/wH4CfAH4AuDXJD3QVTJK0sWG2wP8u8EdV9cdV9QIwB9zcTSxJ0mZSVYNNmPwMcKiq3t0bfifw96rq51a97jBwuDd4DfCVweOO1BXAN8YdYgCt5gazj4vZx2OY7H+jql65euTANzVm7RsaX/S/QVUdA44NsZxtkWShqqbHnWOrWs0NZh8Xs4/HKLIPswvlFHDViuErgT8dLo4kqV/DFPgfAK9NcnWSlwG3AJ/oJpYkaTMD70KpqvNJfg74FLAHuKeqnuws2fbb8bt51tFqbjD7uJh9PDrPPvAvMSVJ4+WZmJLUKAtckhq1qws8yVVJfj/JU0meTHLHuDNtVZI9ST6f5KFxZ9mKJJcleSDJl3vr/0fGnakfSX6x91l5Isn9Sb5r3Jk2kuSeJGeTPLFi3HcneSTJV3t/Xz7OjGtZJ/ev9j4vX0zy20kuG2PEda2VfcVz701SSa7oYlm7usCB88CRqvrbwBuBf9bg5QDuAJ4ad4gBfBD43ar6W8AP0cC/IckB4OeB6aq6luVf3t8y3lSbOg4cWjXuTuDTVfVa4NO94Z3mOBfnfgS4tqpeB/whcNd2h+rTcS7OTpKrgBuAr3W1oF1d4FX1TFU91nv8bZZL5MB4U/UvyZXAjcCHxp1lK5K8Avgx4MMAVfVCVX1zrKH6dwmwN8klwKXs8HMfqupR4NlVo28G7u09vhf46e3M1I+1clfVw1V1vjf4WZbPPdlx1lnnAB8Afok1Tngc1K4u8JWSTAGvBz435ihb8e9Z/kD89ZhzbNX3AV8H/nNv98+Hkuwbd6jNVNVp4NdY3oJ6Bniuqh4eb6qBTFbVM7C8EQO8asx5BvGzwO+MO0S/ktwEnK6qL3Q5XwscSDIBfAz4har61rjz9CPJ24CzVXVi3FkGcAnwBuA/VtXrgefZmT/Gv0hvX/HNwNXA9wL7krxjvKl2nyTvY3n3533jztKPJJcC7wP+Rdfz3vUFnuSlLJf3fVX14LjzbMGbgJuSnGT5SpBvTvKR8Ubq2yngVFVd+GnnAZYLfad7C/AnVfX1qvoO8CDwo2PONIgzSV4N0Pv77Jjz9C3JbcDbgLdXOyexvIbl//S/0Pu+Xgk8luR7hp3xri7wJGF5P+xTVfXr486zFVV1V1VdWVVTLP8i7feqqomtwar6M+DpJNf0Rl0PfGmMkfr1NeCNSS7tfXaup4Ffvq7hE8Btvce3AR8fY5a+JTkE/DJwU1X9xbjz9KuqFqvqVVU11fu+ngLe0PseDGVXFzjLW7HvZHnr9fHen58cd6hd4j3AfUm+CPww8G/GG2dzvZ8YHgAeAxZZ/v7s6FO7k9wPfAa4JsmpJO8CjgI3JPkqy0dFHB1nxrWsk/s3gJcDj/S+q7851pDrWCf7aJbVzk8hkqSVdvsWuCQ1ywKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5Jjfq/OrLUjudGTZoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "distress_companies.hist(column=['Time'], bins=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que la fréquence de la détresse ne semble certainement pas être uniforme dans le temps.\n",
    "\n",
    "Cela indique qu'il peut être malavisé d'obtenir des validations ou des jeux de tests en choisissant simplement certaines entreprises, car nous ne pouvons pas supposer que les différentes entreprises sont indépendantes. L'horodatage lui-même peut être un signal utile (c'est-à-dire si une certaine période représente un état de déclin macroéconomique pour une certaine industrie, ou l'économie dans son ensemble)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f80 = list(df.groupby('Company')['x80'].agg('mean'))\n",
    "f80 = [int(c) for c in f80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation croisée: pour séparer les données en apprentissage, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating dictionary...\n",
      "We can encode categorical feature 80 as a one-hot vector with this many dimensions:\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# Generation de la base d'apprentissage et la bae test par validation croisée\n",
    "\n",
    "datadict = {}\n",
    "distress_dict = {}\n",
    "\n",
    "for i in range (1, total_n+1):\n",
    "    datadict[i] = {}\n",
    "    distress_dict[i] = {}\n",
    "\n",
    "print(\"Populating dictionary...\")\n",
    "for idx, row in df.iterrows():\n",
    "    company = row['Company']\n",
    "    time = int(row['Time'])\n",
    "    \n",
    "    datadict[company][time] = {}\n",
    "    \n",
    "    if row['Financial Distress'] < -0.5:\n",
    "        distress_dict[company][time] = 1\n",
    "    else:\n",
    "        distress_dict[company][time] = 0\n",
    "        \n",
    "    for feat_idx, column in enumerate(row[3:]):\n",
    "        feat = feature_names[feat_idx]\n",
    "        datadict[company][time][feat] = column\n",
    "        \n",
    "# print('Dict population complete. Sample below:')\n",
    "# print(\"\\nData for company 1, time 1:\")\n",
    "# print(datadict[1][1])\n",
    "\n",
    "# print(\"\\nDistress history for company 1:\")\n",
    "# print(distress_dict[1])\n",
    "\n",
    "print('We can encode categorical feature 80 as a one-hot vector with this many dimensions:')\n",
    "print(len(list(set(f80))))\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "label_binarizer.fit(range(max(f80)))\n",
    "f80_oh = label_binarizer.transform(f80)\n",
    "\n",
    "# print(f80_oh[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1678, 203)\n",
      "(687, 203)\n",
      "(499, 203)\n"
     ]
    }
   ],
   "source": [
    "# Make new features as np array. We'll even add x80 back!\n",
    "\n",
    "def rolling_operation(time, train_array, datadict, distress_dict, feature_names, total_n,\n",
    "                         lookback_periods):\n",
    "\n",
    "    for company in range(1, total_n+1):\n",
    "            \n",
    "            all_periods_exist = True\n",
    "            for j in range(0, lookback_periods):\n",
    "                if not time-j in distress_dict[company]:\n",
    "                    all_periods_exist = False\n",
    "            if not all_periods_exist:\n",
    "                continue\n",
    "            \n",
    "            distress_at_eop = distress_dict[company][time]\n",
    "            new_row = [company]\n",
    "\n",
    "            for feature in feature_names:\n",
    "                if feature == 'x80':\n",
    "                    continue\n",
    "                feat_sum = 0.0\n",
    "                variance_arr = []\n",
    "                for j in range(0, lookback_periods):\n",
    "                    feat_sum += datadict[company][time-j][feature]\n",
    "                    variance_arr.append(datadict[company][time-j][feature])\n",
    "                new_row.append(feat_sum)\n",
    "                new_row.append(np.var(variance_arr))\n",
    "                \n",
    "            for j in range(0,len(f80_oh[0])):\n",
    "                new_row.append(f80_oh[company-1][j])\n",
    "\n",
    "            if len(new_row) == ((len(feature_names)-1)*2 + 1 + len(f80_oh[0])) : # we have a complete row\n",
    "                new_row.append(distress_at_eop)\n",
    "                new_row_np = np.asarray(new_row)\n",
    "                train_array.append(new_row_np)\n",
    "    \n",
    "\n",
    "def custom_timeseries_cv(datadict, distress_dict, feature_names, total_n, val_time, test_time, \n",
    "                         lookback_periods, total_periods=14):\n",
    "\n",
    "    # Train data\n",
    "    train_array = []\n",
    "    for _t in range(1, val_time+1):\n",
    "        time = (val_time+1) -_t # Start from time period 10 and work backwards\n",
    "        train_array_np = rolling_operation(time, train_array, datadict, distress_dict, feature_names, total_n,\n",
    "                         lookback_periods)\n",
    "\n",
    "    train_array_np = np.asarray(train_array)\n",
    "    print(train_array_np.shape)\n",
    "    # print(train_array_np[0])\n",
    "    \n",
    "    # Val data\n",
    "    if val_time != test_time:\n",
    "        val_array = []\n",
    "        for time in range(val_time+1, test_time+1):\n",
    "            val_array_np = rolling_operation(time, val_array, datadict, distress_dict, feature_names, total_n,\n",
    "                         lookback_periods)\n",
    "\n",
    "        val_array_np = np.asarray(val_array)\n",
    "        print(val_array_np.shape)\n",
    "        # print(val_array_np[0])\n",
    "    else:\n",
    "        val_array_np = None\n",
    "\n",
    "    # Test data\n",
    "    test_array = []\n",
    "    # start from time period 11 and work forwards\n",
    "    for time in range(test_time+1,total_periods+1):\n",
    "        test_array_np = rolling_operation(time, test_array, datadict, distress_dict, feature_names, total_n,\n",
    "                         lookback_periods)\n",
    "\n",
    "    test_array_np = np.asarray(test_array)\n",
    "    print(test_array_np.shape)\n",
    "    # print(test_array_np[0])\n",
    "    \n",
    "    return train_array_np, val_array_np, test_array_np\n",
    "\n",
    "# Generate our sets\n",
    "train_array_np, val_array_np, test_array_np = custom_timeseries_cv(datadict, distress_dict, feature_names, total_n,\n",
    "                                                     val_time=9, test_time=12, lookback_periods=3, total_periods=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.00000000e+00  4.84160000e+00  5.97729556e-03  7.18260000e-01\n",
      "  3.66930467e-04  1.70750000e+00  2.57254689e-04  3.07451000e+00\n",
      "  1.79494967e-02  9.67730000e-01  5.10969622e-04  9.34370000e-01\n",
      "  2.40172822e-04  3.26607000e+00  3.11568702e-02  7.06260000e-01\n",
      "  2.11975800e-04  1.67120000e+00  2.93949882e-03  8.59080000e-01\n",
      "  9.40618667e-05  2.47056000e+00  5.89100067e-04  5.68560000e+01\n",
      "  1.00793887e+01  1.29250000e+00  2.57254689e-04  3.97310000e+00\n",
      "  7.73550889e-03  1.07744000e+01  3.44810300e+00  9.52770000e-01\n",
      "  4.92798067e-04  8.75760000e+00  1.83738887e-01  6.80560000e-02\n",
      "  8.40756422e-06  5.24840000e-02  1.99125982e-05  1.34072000e-01\n",
      "  5.83302969e-05  3.72680000e+00  2.07546422e-02  1.90716000e+01\n",
      "  2.33013109e+00  1.10259000e+00  1.80993620e-03  1.53617000e+00\n",
      "  1.43273636e-03  5.55640000e+03  3.09414489e+04  3.96100000e+01\n",
      "  1.04226889e-01  9.95560000e+00  3.29755936e-01  1.31819000e+00\n",
      "  4.81916144e-02  1.71329000e-01  5.60041134e-04  1.66177000e+00\n",
      "  5.82454896e-03  1.01653000e+01  2.61197549e-01  1.66934000e+00\n",
      "  1.72860591e-02  2.69589000e+00  1.97227007e-03  1.39316000e+01\n",
      "  5.85157449e-01  3.84855000e+02  3.22791972e+03  8.71910000e-01\n",
      "  4.32784956e-04  3.93246000e-01  2.51951303e-03  6.85490000e-02\n",
      "  3.16836222e-05  7.68447000e-01  7.55001881e-02  5.00730000e-01\n",
      "  6.04728067e-04  7.16530000e+00  1.30112002e-01  1.04403000e+00\n",
      "  4.18326338e-02  7.87260000e+00  8.52306467e-02  4.42410000e+00\n",
      "  7.91623467e-02  2.16894000e+00  6.08114067e-04  1.26186000e+00\n",
      "  1.00894940e-03  3.98060000e+00  7.82403556e-03  9.98420000e+03\n",
      "  1.47019356e+04  3.57980000e+00  1.71026956e-02  1.89741000e+00\n",
      "  1.80993620e-03  3.96560000e+01  4.84975556e-02  9.78350000e-01\n",
      "  4.82643622e-04  1.11320000e+00  1.44594956e-04  5.65800000e+03\n",
      "  1.28413647e+05  4.25133000e-01  5.59411547e-03  6.94720000e-01\n",
      "  4.69371496e-03  1.37292000e+00  6.33374865e-02 -4.02069000e-03\n",
      "  9.24633520e-07 -3.75638000e-03  6.03815757e-07  6.67780000e-01\n",
      "  1.66602222e-06  5.65661390e+00  7.37758304e+00  5.66873000e+00\n",
      "  2.26275566e+01  4.07602000e+00  1.99885046e+01  6.46530000e+00\n",
      "  9.21364898e+00  1.22200000e+02  2.03925367e+03  6.49910000e+01\n",
      "  1.67845402e+01  3.58000000e+01  1.60222222e+00  3.02475000e+04\n",
      "  1.50634727e+05  9.53599000e+01  3.91943789e+02  4.86000000e+01\n",
      "  4.27466667e+01  5.00181000e+01  3.34007056e+02  6.00000000e+00\n",
      "  2.66666667e+00  8.30000000e+01  2.22222222e-01  2.58494000e+02\n",
      "  3.34821149e+01  2.21620000e+02  4.38587556e+01  1.97848000e+02\n",
      "  3.97711829e+01  5.05000000e+01  7.22222222e-01  3.70000000e+01\n",
      "  2.22222222e-01 -1.16000000e+01  4.55022222e+01  6.64320000e+00\n",
      "  1.54805000e-02  4.20000000e+01  6.66666667e-01  1.02000000e+02\n",
      "  6.66666667e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 1]\n",
      "[ 2.00000000e+00  4.98920000e+00  7.05313556e-03  6.64790000e-01\n",
      "  1.93806489e-04  1.67700000e+00  5.59272467e-04  2.70452000e+00\n",
      "  1.58939967e-02  9.12140000e-01  2.32525489e-04  9.64330000e-01\n",
      "  2.07616289e-04  3.76270000e+00  9.64396222e-03  7.44890000e-01\n",
      "  3.17221089e-04  1.51709000e+00  3.62134996e-03  8.91270000e-01\n",
      "  2.22178067e-04  2.43564000e+00  9.24332067e-04  4.68630000e+01\n",
      "  9.61304867e+00  1.32300000e+00  5.59272467e-04  3.82280000e+00\n",
      "  1.55878489e-02  9.27640000e+00  4.74077714e+00  1.02389000e+00\n",
      "  8.51558956e-04  9.17700000e+00  6.87114467e-02  5.40937000e-02\n",
      "  8.96535674e-05  6.91420000e-02  3.70592329e-05  1.08538000e-01\n",
      "  3.55784374e-04  3.31870000e+00  1.24021956e-02  1.59335000e+01\n",
      "  3.25301143e+00  1.21807000e+00  2.28751016e-03  1.47131000e+00\n",
      "  1.98476702e-03  5.16840000e+03  5.05656267e+04  4.05670000e+01\n",
      "  2.68162222e-02  8.48350000e+00  2.82975869e-01  1.18850000e+00\n",
      "  6.03847800e-02  2.05697000e-01  5.12208515e-04  1.83258000e+00\n",
      "  1.35816800e-04  1.30101000e+01  2.43544658e+00  2.06834000e+00\n",
      "  7.47154576e-03  2.62712000e+00  1.91419762e-03  1.54440000e+01\n",
      "  2.84984000e-03  5.33385000e+02  8.17545402e+03  8.18070000e-01\n",
      "  4.70512667e-05  4.60446000e-01  2.13190343e-03  5.83666000e-02\n",
      "  1.00589960e-04  7.19927000e-01  7.84250491e-02  5.40300000e-01\n",
      "  9.31576267e-04  6.19760000e+00  1.65981416e-01  8.78950000e-01\n",
      "  4.87986430e-02  7.51650000e+00  1.13956047e-01  3.86060000e+00\n",
      "  1.10956269e-01  2.18816000e+00  2.48016689e-04  1.18826000e+00\n",
      "  6.89956222e-05  3.83120000e+00  1.57588356e-02  1.02076000e+04\n",
      "  1.72984222e+03  3.36230000e+00  2.72043622e-02  1.78193000e+00\n",
      "  2.28751016e-03  4.02280000e+01  2.73755556e-03  1.04799000e+00\n",
      "  8.90579267e-04  1.08001000e+00  2.15706889e-05  6.43870000e+03\n",
      "  1.41885622e+04  3.60249000e-01  6.37873605e-03  5.25060000e-01\n",
      "  5.62682467e-04  1.47696000e+00  4.49993961e-02 -2.00285000e-03\n",
      "  5.09486429e-09 -2.28753000e-03  2.62084472e-08  6.74410000e-01\n",
      "  3.37508889e-06  8.79406190e+00  5.46359342e+00  9.86050000e+00\n",
      "  2.05912227e+01  6.56813000e+00  1.40829183e+01 -8.61150000e+00\n",
      "  2.33446311e+01  1.54389000e+02  9.45135254e+02  6.92070000e+01\n",
      "  4.57968867e+00  3.77000000e+01  4.62222222e-01  3.41482000e+04\n",
      "  2.45213441e+06  1.05098000e+02  2.37759154e+02  4.47000000e+01\n",
      "  2.22066667e+01  4.21881000e+01  2.17521190e+02  8.00000000e+00\n",
      "  8.88888889e-01  7.70000000e+01  6.88888889e+00  2.78543000e+02\n",
      "  3.97552242e+01  2.55500000e+02  1.23815556e+02  2.38377000e+02\n",
      "  2.29753122e+02  4.96250000e+01  2.11805556e-01  3.95000000e+01\n",
      "  1.05555556e+00 -5.20000000e+00  1.39288889e+01  6.87840000e+00\n",
      "  1.58802000e-03  4.50000000e+01  6.66666667e-01  1.05000000e+02\n",
      "  6.66666667e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[ 2.00000000e+00  5.89540000e+00  5.69868289e-02  8.09160000e-01\n",
      "  3.52779687e-03  1.42733000e+00  2.58959642e-03  2.66710000e+00\n",
      "  1.32720394e-02  1.12728000e+00  5.22057787e-03  1.26743000e+00\n",
      "  5.20633696e-03  3.98430000e+00  2.74046067e-02  8.99040000e-01\n",
      "  1.12914447e-03  1.52387000e+00  4.79299669e-03  1.09053000e+00\n",
      "  3.47958327e-03  2.61266000e+00  8.53158756e-04  3.03915000e+01\n",
      "  1.73587017e+00  1.57267000e+00  2.58959642e-03  2.78124000e+00\n",
      "  4.03222849e-02  1.21293000e+01  4.47079740e-01  1.25678000e+00\n",
      "  1.01210509e-03  6.47390000e+00  1.53829356e-02  7.91840000e-02\n",
      "  8.56717096e-05  1.25154000e-01  9.44728467e-06  1.79922000e-01\n",
      "  5.93303581e-04  3.05258000e+00  1.01980654e-02  2.31214000e+01\n",
      "  5.72150144e+00  1.44957000e+00  7.70449867e-04  1.34522000e+00\n",
      "  1.85923602e-03  5.62840000e+03  2.32439056e+05  4.30320000e+01\n",
      "  4.59246667e-02  6.36900000e+00  1.52284467e-02  1.00990000e+00\n",
      "  6.23398096e-03  8.21080000e-02  1.25259137e-04  1.76680000e+00\n",
      "  1.09200896e-03  2.75009000e+01  6.78098882e-01  2.01304000e+00\n",
      "  5.05056096e-03  2.83092000e+00  4.03816200e-04  1.25551000e+01\n",
      "  9.10846956e-02  2.73992000e+02  1.92773750e+02  9.23210000e-01\n",
      "  3.51733682e-03  1.63272000e-01  6.91326949e-04  9.06330000e-02\n",
      "  1.05898514e-04  1.37533000e+00  5.25944435e-02  3.73920000e-01\n",
      "  9.01497800e-04  5.07100000e+00  4.05274889e-03  1.77750000e+00\n",
      "  2.89285512e-01  1.35442000e+01  1.64423873e+00  7.13630000e+00\n",
      "  7.98504482e-01  2.39924000e+00  4.26518816e-03  1.75629000e+00\n",
      "  3.02753781e-02  2.78357000e+00  4.05857160e-02  1.08785000e+04\n",
      "  2.63754069e+05  2.61796000e+00  3.18799190e-02  1.55043000e+00\n",
      "  7.70449867e-04  4.26510000e+01  1.20480667e-01  1.29189000e+00\n",
      "  9.42868067e-04  1.29824000e+00  6.14847056e-03  1.19361000e+04\n",
      "  1.17949472e+06  5.95003000e-01  2.12306923e-02  6.37910000e-01\n",
      "  6.52681356e-04  1.88630000e-01  1.91758844e-02  1.26180000e-04\n",
      "  3.53808720e-09  1.33240000e-04  3.94508836e-09  6.63060000e-01\n",
      "  2.30204667e-05 -4.82431000e+00  2.07294809e+01 -1.09630900e+01\n",
      "  3.42400794e+01 -2.16457000e+01  1.88924620e+02 -4.38508000e+01\n",
      "  5.28199221e+01  1.33693000e+02  2.75768211e+03  9.12030000e+01\n",
      "  4.53775327e+01  3.32000000e+01  6.48888889e-01  9.06990000e+04\n",
      "  8.86537867e+06 -8.01107000e+01  6.40507654e+02  8.08000000e+01\n",
      "  6.71622222e+01  4.79360000e+01  3.85133267e+02  4.00000000e+00\n",
      "  8.88888889e-01  9.00000000e+01  2.66666667e+00  2.71500000e+02\n",
      "  6.10666667e+00  5.09600000e+02  8.99082222e+02  5.15000000e+02\n",
      "  8.87095556e+02  6.20000000e+01  8.88888889e-01  5.10000000e+01\n",
      "  1.25000000e+01 -2.98000000e+01  1.36328889e+02  7.56720000e+00\n",
      "  2.64383647e-01  5.40000000e+01  6.66666667e-01  1.14000000e+02\n",
      "  6.66666667e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_array_np[:,0:train_array_np.shape[1]-1]\n",
    "y_train = train_array_np[:,-1].astype(int)\n",
    "\n",
    "X_val = val_array_np[:,0:val_array_np.shape[1]-1]\n",
    "y_val = val_array_np[:,-1].astype(int)\n",
    "\n",
    "X_test = test_array_np[:,0:test_array_np.shape[1]-1]\n",
    "y_test = test_array_np[:,-1].astype(int)\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "print(X_train[0,:])\n",
    "print(y_train)\n",
    "\n",
    "print(X_val[0,:])\n",
    "print(y_val)\n",
    "\n",
    "print(X_test[0,:])\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def model_trial(model_type, hyperparam):\n",
    "    if model_type in ['logistic-regression']:\n",
    "        # Logistic Regression. Try 11, l2 penalty, understand one-vs-rest vs multinomial (cross-entropy) \n",
    "        model = LogisticRegression(penalty=hyperparam, solver='saga', max_iter=4000)\n",
    "    elif model_type in ['decision-tree']:\n",
    "        model = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=None)\n",
    "    elif model_type in ['random-forest']:\n",
    "        model = RandomForestClassifier(n_estimators=hyperparam)\n",
    "    else:\n",
    "        print(\"Warning: model {} not recognized.\".format(model_type))\n",
    "        \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    print(\"Mean acc: %f\" % model.score(X_val, y_val))\n",
    "    print(\"F1: %f\" % f1)\n",
    "    print(\"Recall: %f\" % recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Logistic regression, l1:--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenoa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acc: 0.976710\n",
      "F1: 0.000000\n",
      "Recall: 0.000000\n",
      "--------------------Logistic regression, l2:--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenoa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean acc: 0.976710\n",
      "F1: 0.000000\n",
      "Recall: 0.000000\n",
      "--------------------Decision tree:--------------------\n",
      "Mean acc: 0.928675\n",
      "F1: 0.140351\n",
      "Recall: 0.250000\n",
      "--------------------Random forest, 2 estimators:--------------------\n",
      "Mean acc: 0.970888\n",
      "F1: 0.230769\n",
      "Recall: 0.187500\n",
      "--------------------Random forest, 4 estimators:--------------------\n",
      "Mean acc: 0.967977\n",
      "F1: 0.214286\n",
      "Recall: 0.187500\n",
      "--------------------Random forest, 10 estimators:--------------------\n",
      "Mean acc: 0.970888\n",
      "F1: 0.166667\n",
      "Recall: 0.125000\n",
      "--------------------Random forest, 50 estimators:--------------------\n",
      "Mean acc: 0.975255\n",
      "F1: 0.105263\n",
      "Recall: 0.062500\n",
      "--------------------Random forest, 100 estimators:--------------------\n",
      "Mean acc: 0.973799\n",
      "F1: 0.000000\n",
      "Recall: 0.000000\n",
      "--------------------Random forest, 1000 estimators:--------------------\n",
      "Mean acc: 0.978166\n",
      "F1: 0.117647\n",
      "Recall: 0.062500\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*20 + \"Logistic regression, l1:\" + \"-\"*20)\n",
    "model_trial('logistic-regression', 'l1')\n",
    "\n",
    "print(\"-\"*20 + \"Logistic regression, l2:\" + \"-\"*20)\n",
    "model_trial('logistic-regression', 'l2')\n",
    "\n",
    "print(\"-\"*20 + \"Decision tree:\" + \"-\"*20)\n",
    "model_trial('decision-tree', None)\n",
    "\n",
    "for i in [2, 4, 10, 50, 100, 1000]:\n",
    "    print(\"-\"*20 + \"Random forest, {} estimators:\".format(i) + \"-\"*20)\n",
    "    model_trial('random-forest', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les algorithmes de Machine Learning utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import linear_model\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "clf = knn.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "acc_knb_model=roc_auc_score(y_test, y_pred)*100\n",
    "acc_knb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenoa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 0.2)\n",
    "clf1 = lr.fit(X_train, y_train)\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "acc_log_reg=roc_auc_score(y_test, y_pred1)*100\n",
    "acc_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.95175438596491"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = GaussianNB().fit(X_train, y_train)\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "acc_nb=roc_auc_score(y_test, y_pred2)*100\n",
    "acc_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.12938596491229"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = tree.DecisionTreeClassifier().fit(X_train, y_train)\n",
    "y_pred3 = clf3.predict(X_test)\n",
    "acc_dt=roc_auc_score(y_test, y_pred3)*100\n",
    "acc_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.6875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = RandomForestClassifier(max_depth=5, random_state=0).fit(X_train, y_train)\n",
    "y_pred4 = clf4.predict(X_test)\n",
    "acc_rmf_model=roc_auc_score(y_test, y_pred4)*100\n",
    "acc_rmf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5 = SVC(gamma='auto').fit(X_train, y_train)\n",
    "y_pred5 = clf5.predict(X_test)\n",
    "acc_svm_model=roc_auc_score(y_test, y_pred5)*100\n",
    "acc_svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.2920143027"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_model=SGDClassifier()\n",
    "sgd_model.fit(X_train,y_train)\n",
    "sgd_pred=sgd_model.predict(X_test)\n",
    "acc_sgd=round(sgd_model.score(X_train,y_train)*100,10)\n",
    "acc_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenoa\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:39:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model=XGBClassifier()\n",
    "xgb_model.fit(X_train,y_train)\n",
    "xgb_pred=xgb_model.predict(X_test)\n",
    "acc_xgb=round(xgb_model.score(X_train,y_train)*100,10)\n",
    "acc_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier()\n",
    "lgbm.fit(X_train,y_train)\n",
    "lgbm_pred=lgbm.predict(X_test)\n",
    "acc_lgbm=round(lgbm.score(X_train,y_train)*100,10)\n",
    "acc_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100.000000</th>\n",
       "      <td>XGBoost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.000000</th>\n",
       "      <td>LightGBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95.292014</th>\n",
       "      <td>Stochastic Gradient Decent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.129386</th>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51.951754</th>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.000000</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.000000</th>\n",
       "      <td>KNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.000000</th>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.687500</th>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model\n",
       "Score                                 \n",
       "100.000000                     XGBoost\n",
       "100.000000                    LightGBM\n",
       "95.292014   Stochastic Gradient Decent\n",
       "66.129386                Decision Tree\n",
       "51.951754                  Naive Bayes\n",
       "50.000000      Support Vector Machines\n",
       "50.000000                          KNN\n",
       "50.000000          Logistic Regression\n",
       "49.687500                Random Forest"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest','Stochastic Gradient Decent','Naive Bayes','XGBoost','LightGBM','Decision Tree'],\n",
    "    'Score': [acc_svm_model, acc_knb_model, acc_log_reg, \n",
    "              acc_rmf_model,acc_sgd,acc_nb,acc_xgb,acc_lgbm,acc_dt]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur modèle de prévision de la détresse financière serait ici le gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
